# services/chatbot_service.py

import os
import json
import random
from pathlib import Path
from dotenv import load_dotenv
from openai import OpenAI
import chromadb
from chromadb.config import Settings

load_dotenv()
BASE_DIR = Path(__file__).resolve().parent.parent

class ChatbotService:
    def __init__(self):
        print("[ChatbotService] ì´ˆê¸°í™” ì¤‘...")
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key or len(api_key) < 10:
            raise ValueError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        self.client = OpenAI(api_key=api_key)
        
        # ChromaDB ì´ˆê¸°í™”
        print("[ChromaDB] ë²¡í„° DB ì´ˆê¸°í™” ì¤‘...")
        chroma_path = BASE_DIR / "static/data/chatbot/chardb_embedding"
        chroma_path.mkdir(parents=True, exist_ok=True)
        
        self.chroma_client = chromadb.PersistentClient(
            path=str(chroma_path),
            settings=Settings(
                anonymized_telemetry=False,
                allow_reset=True
            )
        )
        
        self.game_session = {}
        self.start_new_game()
        print("[ChatbotService] ì´ˆê¸°í™” ì™„ë£Œ. ìƒˆë¡œìš´ ê²Œìž„ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")

    def start_new_game(self):
        suspect_ids = ['leonard', 'walter', 'clara']
        killer = random.choice(suspect_ids)
        nathan_script = self._load_nathan_script()
        if nathan_script is None:
            self.game_session = {"mode": "error", "error_message": "Nathan script not found."}
            return
        
        active_knowledge = self._create_active_knowledge(suspect_ids, killer)
        # [ìˆ˜ì •] ë¶ˆí•„ìš”í•œ clues ë³€ìˆ˜ í• ë‹¹ì„ ì œê±°í•©ë‹ˆë‹¤.
        self.game_session = {
            "killer": killer, "nathan_script": nathan_script,
            "active_knowledge": active_knowledge, "history": {s_id: [] for s_id in suspect_ids},
            "mode": "briefing", "questions_left": 15,
            "mid_report_done": False
        }
        print(f"--- ìƒˆë¡œìš´ ê²Œìž„ ì‹œìž‘ --- ë²”ì¸ì€ '{killer}' ìž…ë‹ˆë‹¤.")
    def generate_response(self, user_message: str, suspect_id: str = None) -> dict:
        # 1. ìƒí™©ì— ë§žëŠ” í•¸ë“¤ëŸ¬ë¥¼ í˜¸ì¶œí•˜ì—¬ ê²°ê³¼ë¥¼ ë°›ìŠµë‹ˆë‹¤.
        if user_message.strip().lower() == "init":
            handler_result = self._handle_briefing(user_message)
        else:
            current_mode = self.game_session.get("mode")
            if current_mode == "briefing":
                handler_result = self._handle_briefing(user_message)
            elif current_mode == "interrogation":
                if not suspect_id:
                    handler_result = {"reply": "ì‹¬ë¬¸í•  ìš©ì˜ìžë¥¼ ì„ íƒí•´ ì£¼ì‹­ì‹œì˜¤.", "sender": "system"}
                else:
                    handler_result = self._handle_interrogation(user_message, suspect_id)
            else:
                handler_result = {"reply": "ê²Œìž„ ëª¨ë“œ ì„¤ì •ì— ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", "sender": "system"}

        # 2. í•¸ë“¤ëŸ¬ê°€ ë°˜í™˜í•œ ê²°ê³¼ì— ìµœì‹  ìƒíƒœ ì •ë³´ë§Œ ë§ë¶™ì—¬ ìµœì¢… ì‘ë‹µì„ ì™„ì„±í•©ë‹ˆë‹¤.
        final_response = handler_result.copy()
        final_response["questions_left"] = self.game_session.get("questions_left", 0)
        final_response["mode"] = self.game_session.get("mode")

        return final_response
# services/chatbot_service.py íŒŒì¼ì—ì„œ _handle_briefing í•¨ìˆ˜ë¥¼ ì•„ëž˜ ì½”ë“œë¡œ êµì²´í•˜ì„¸ìš”.

    def _handle_briefing(self, user_message: str) -> dict:
        script_briefing = self.game_session["nathan_script"]["briefing"]
        
        if user_message.strip().lower() == "init":
            initial_scenes = script_briefing.get("scenes", [])
            return { "messages": initial_scenes }
        
        if any(keyword in user_message.lower() for keyword in ["ì•Œê² ìŠµë‹ˆë‹¤", "ì•Œê² ", "ì‹œìž‘", "ë„¤", "ê³„ì†"]):
            self.game_session["mode"] = "interrogation"
            
            report_scenes_template = script_briefing.get("report_scenes", [])
            killer = self.game_session.get("killer") # í˜„ìž¬ ê²Œìž„ì˜ ë²”ì¸ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.

            processed_scenes = []
            for scene in report_scenes_template:
                scene_copy = scene.copy() # ì›ë³¸ ë°ì´í„° ìˆ˜ì •ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ë³µì‚¬
                
                # [í•µì‹¬ ìˆ˜ì •] 'conditional_image' í‚¤ê°€ ìžˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
                if "conditional_image" in scene_copy:
                    image_options = scene_copy.pop("conditional_image") # conditional_imageëŠ” ì œê±°
                    
                    # ë²”ì¸ì— ë§žëŠ” ì´ë¯¸ì§€ë¥¼ ì„ íƒí•˜ê±°ë‚˜, ì—†ìœ¼ë©´ default ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
                    image_to_use = image_options.get(killer, image_options.get("default"))
                    
                    if image_to_use:
                        scene_copy["image"] = image_to_use # ìµœì¢…ì ìœ¼ë¡œ 'image' í‚¤ì— í• ë‹¹
                
                processed_scenes.append(scene_copy)

            return {
                "messages": processed_scenes,
                "mode": "interrogation"
            }

        return {"reply": "ì¤€ë¹„ë˜ì‹œë©´ 'ì•Œê² ìŠµë‹ˆë‹¤'ë¼ê³  ë§ì”€í•´ì£¼ì‹­ì‹œì˜¤.", "sender": "nathan"}
    
    def _handle_interrogation(self, user_message: str, suspect_id: str) -> dict:
        try:
            if self.game_session["questions_left"] <= 0:
                return {"reply": "ë” ì´ìƒ ì§ˆë¬¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì´ì œ ë²”ì¸ì„ ì§€ëª©í•´ì•¼ í•©ë‹ˆë‹¤.", "sender": "system", "image": None}

            # --- ìš©ì˜ìž ë‹µë³€ ìƒì„± (ë²¡í„° ê²€ìƒ‰ RAG) ---
            is_killer = (self.game_session["killer"] == suspect_id)
            suspect_config = self._load_suspect_config(suspect_id)
            knowledge_base = self.game_session["active_knowledge"][suspect_id]
            retrieved_doc = self._search_similar(user_message, knowledge_base, suspect_id)
            
            # ì¦ê±° ì´ë¯¸ì§€ê°€ ìžˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©, ì—†ìœ¼ë©´ ê°ì • ì´ë¯¸ì§€ ì‚¬ìš©
            evidence_image = retrieved_doc.get("image") if retrieved_doc else None
            
            system_prompt = suspect_config['system_prompt_killer'] if is_killer else suspect_config['system_prompt_innocent']
            history = self._get_conversation_history(suspect_id, user_message)
            final_prompt = self._build_final_prompt(suspect_config, system_prompt, history, user_message, retrieved_doc)
            response = self.client.chat.completions.create(model="gpt-4o-mini", messages=[{"role": "user", "content": final_prompt}], temperature=0.7, max_tokens=300)
            reply = response.choices[0].message.content.strip()
            
            # --- ê°ì • ë¶„ì„ ë° ì´ë¯¸ì§€ ì„ íƒ ---
            if evidence_image:
                # ì¦ê±° ì´ë¯¸ì§€ê°€ ìžˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
                image_info_to_show = evidence_image
            else:
                # ì¦ê±° ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ ê°ì • ì´ë¯¸ì§€ ì‚¬ìš©
                emotion = self._analyze_emotion(reply, suspect_id)
                emotion_image = self._get_emotion_image(suspect_id, emotion)
                image_info_to_show = emotion_image
            
            # --- ìƒíƒœ ì—…ë°ì´íŠ¸ (ê¸°ì¡´ ë¡œì§) ---
            self.game_session["questions_left"] -= 1
            self._save_to_history(suspect_id, user_message, reply)

            # --- [í•µì‹¬ ìˆ˜ì •] ìµœì¢… ì‘ë‹µ êµ¬ì„± ---
            # 1. ë¨¼ì € ìš©ì˜ìžì˜ ë‹µë³€ì„ ê¸°ë³¸ ì‘ë‹µ ê°ì²´ì— ë‹´ìŠµë‹ˆë‹¤.
            final_response = {"reply": reply, "sender": suspect_id, "image": image_info_to_show}

            # 2. ê·¸ ì§í›„, ë‚¨ì€ ì§ˆë¬¸ì´ 8ê°œì¸ì§€(7ë²ˆ ì§ˆë¬¸ì´ ëë‚œ ìƒíƒœì¸ì§€) í™•ì¸í•©ë‹ˆë‹¤.
            if self.game_session.get("questions_left") == 8 and not self.game_session.get("mid_report_done"):
                self.game_session["mid_report_done"] = True
                killer = self.game_session["killer"]
                mid_game_report_scenes = self.game_session["nathan_script"]["mid_game_report"]
                
                processed_scenes = []
                for scene in mid_game_report_scenes:
                    scene_copy = scene.copy()
                    if "conditional_content" in scene_copy:
                        content = scene_copy.pop("conditional_content")[killer]
                        # conditional_contentì˜ textì™€ imageë¥¼ scene_copyì— í•©ì¹©ë‹ˆë‹¤.
                        scene_copy["reply"] = scene_copy.get("reply", "") + content.get("text", "")
                        scene_copy["image"] = content.get("image")
                    processed_scenes.append(scene_copy)
                
                # 'additional_messages' í‚¤ì— ìˆœì°¨ì ìœ¼ë¡œ ë³´ì—¬ì¤„ ë³´ê³  ë‚´ìš©ì„ ë‹´ìŠµë‹ˆë‹¤.
                final_response["additional_messages"] = processed_scenes
            
            return final_response
            
        except Exception as e:
            import traceback; traceback.print_exc()
            return {"reply": "ì£„ì†¡í•©ë‹ˆë‹¤. ìƒê°ì— ìž ì‹œ ì˜¤ë¥˜ê°€ ìƒê¸´ ê²ƒ ê°™ìŠµë‹ˆë‹¤...", "sender": "suspect_id", "image": None}
# services/chatbot_service.py ì˜ make_accusation í•¨ìˆ˜

    def make_accusation(self, accused_suspect_id: str) -> dict:
        real_killer_id = self.game_session["killer"]
        is_correct = (accused_suspect_id == real_killer_id)
        
        final_prompt = ""
        sender_id = accused_suspect_id
        
        if is_correct:
            killer_config = self._load_suspect_config(real_killer_id)
            # === [ìˆ˜ì •] ë²”ì¸ì˜ 'ìžë°±ìš©' ìƒì„¸ ì •ë³´ë¥¼ knowledge.jsonì—ì„œ ê°€ì ¸ì˜´ ===
            killer_knowledge = self._load_suspect_knowledge(real_killer_id)
            confession_details = killer_knowledge.get("killer_confession_details", {})
            
            persona_str = "\n".join([f"- {key}: {value}" for key, value in killer_config.get("persona_details", {}).items()])
            final_prompt = f"""
# ì´ê´„ ì§€ì‹œ
ë„ˆëŠ” ë§ˆì¹¨ë‚´ ì •ì²´ê°€ íƒ„ë¡œë‚œ ë²”ì¸ '{killer_config['name']}'ì´ë‹¤. íƒì • 'Adrian Vale'ì´ ë„ˆë¥¼ ë²”ì¸ìœ¼ë¡œ ì§€ëª©í–ˆë‹¤.
# ë„ˆì˜ ìƒì„¸ íŽ˜ë¥´ì†Œë‚˜
{persona_str}
# ë„ˆì˜ í˜„ìž¬ ë§ˆìŒê°€ì§
{killer_config['system_prompt_killer']}
# ë„ˆì˜ ë²”í–‰ ê¸°ë¡ (ì´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ìžë°±í•˜ë¼)
- ë²”í–‰ ë™ê¸°(ì™œ): {confession_details.get('why')}
- ë²”í–‰ ë°©ì‹(ì–´ë–»ê²Œ): {confession_details.get('how')}
# í•µì‹¬ ìž„ë¬´
íƒì •ì´ ë„ˆë¥¼ ë²”ì¸ìœ¼ë¡œ ì§€ëª©í•œ ì´ ë§ˆì§€ë§‰ ìˆœê°„, ë„ˆì˜ íŽ˜ë¥´ì†Œë‚˜ì— ë§žì¶° ëª¨ë“  ê²ƒì„ ìžë°±í•˜ëŠ” ê·¹ì ì¸ ìµœì¢… ë³€ë¡ ì„ í•˜ë¼. ìœ„ì˜ 'ë„ˆì˜ ë²”í–‰ ê¸°ë¡'ì— ìžˆëŠ” ë™ê¸°ì™€ ë°©ì‹ì„ ë°˜ë“œì‹œ í¬í•¨í•˜ì—¬ ì ˆì ˆí•˜ê²Œ í† ë¡œí•˜ë©° ëŒ€ì‚¬ë¥¼ ë§ˆë¬´ë¦¬í•˜ë¼."""
        else:
            innocent_config = self._load_suspect_config(accused_suspect_id)
            killer_config = self._load_suspect_config(real_killer_id)
            sender_id = "system" 
            
            # === [ìˆ˜ì •] ì§„ë²”ì˜ 'ë²”í–‰ ê¸°ë¡'ì„ knowledge.jsonì—ì„œ ê°€ì ¸ì˜´ ===
            killer_knowledge = self._load_suspect_knowledge(real_killer_id)
            confession_details = killer_knowledge.get("killer_confession_details", {})
            
            innocent_persona_str = "\n".join([f"- {key}: {value}" for key, value in innocent_config.get("persona_details", {}).items()])
            final_prompt = f"""
# ì´ê´„ ì§€ì‹œ
ë‹¹ì‹ ì€ ì‚¬ê±´ì˜ ì§„ì‹¤ì„ ì„¤ëª…í•˜ëŠ” 'ì‚¬ê±´ í•´ì„¤ìž'ì´ë‹¤. ì ˆëŒ€ë¡œ ìƒˆë¡œìš´ ì´ì•¼ê¸°ë¥¼ ì°½ìž‘í•˜ì§€ ë§ê³ , ì•„ëž˜ì— ì£¼ì–´ì§„ 'ì‚¬ì‹¤'ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ì„œìˆ í•˜ë¼.

# ìƒí™©
íƒì • 'Adrian Vale'ì´ '{innocent_config['name']}'ì„ ë²”ì¸ìœ¼ë¡œ ì§€ëª©í–ˆì§€ë§Œ, í‹€ë ¸ë‹¤.

# í•µì‹¬ ìž„ë¬´
1. ë¨¼ì €, ì–µìš¸í•˜ê²Œ ì§€ëª©ëœ '{innocent_config['name']}'ì˜ íŽ˜ë¥´ì†Œë‚˜ë¥¼ ì°¸ê³ í•˜ì—¬ ì˜ ì–µìš¸í•¨ì´ ë‹´ê¸´ ì§§ì€ ë°˜ë°• ëŒ€ì‚¬ë¥¼ ìƒì„±í•˜ë¼.
   - íŽ˜ë¥´ì†Œë‚˜: {innocent_persona_str}
   - ìƒí™©: {innocent_config['system_prompt_innocent']}

2. ì´ì–´ì„œ, ì•„ëž˜ ì£¼ì–´ì§„ 'ì‚¬ê±´ì˜ ì§„ì‹¤' ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ë‹´ë‹´í•˜ê³  ê°ê´€ì ì¸ í†¤ì˜ ë‚˜ë ˆì´ì…˜ì„ ìž‘ì„±í•˜ë¼.
   - **ì‚¬ê±´ì˜ ì§„ì‹¤ (Fact Sheet):**
     - ì§„ë²”: {killer_config['name']}
     - ì§„ë²”ì˜ ë™ê¸°(ì™œ): {confession_details.get('why')}
     - ì§„ë²”ì˜ ë²”í–‰ ë°©ì‹(ì–´ë–»ê²Œ): {confession_details.get('how')}
"""

        response = self.client.chat.completions.create(model="gpt-4o-mini", messages=[{"role": "user", "content": final_prompt}], temperature=0.7, max_tokens=500)
        final_statement = response.choices[0].message.content.strip()
        
        # ê°ì • ë¶„ì„ ë° ì´ë¯¸ì§€ ì¶”ê°€
        emotion = self._analyze_emotion(final_statement, accused_suspect_id)
        emotion_image = self._get_emotion_image(accused_suspect_id, emotion)

        return {
            "result": "success" if is_correct else "failure",
            "final_statement": final_statement,
            "sender": sender_id,
            "image": emotion_image,
            "is_game_over": True
        }
    def get_recommended_questions(self, suspect_id: str) -> list:
        knowledge = self._load_suspect_knowledge(suspect_id)
        return knowledge.get("recommended_questions", []) if knowledge else []
        
# services/chatbot_service.py ì˜ _build_final_prompt í•¨ìˆ˜

    def _build_final_prompt(self, suspect_config, system_prompt, history, user_message, retrieved_doc):
        persona_str = "\n".join([f"- {key}: {value}" for key, value in suspect_config.get("persona_details", {}).items()])
        
        case_brief = f"""
### ë°°ê²½ ì •ë³´
- ì‚¬ê±´: í• ë¡œìŠ¬ëž ìŠ¤í…Œì´ì…˜ ì‚´ì¸ì‚¬ê±´
- í”¼í•´ìž: ê¸°ìž, Elias Cole
- ë‹¹ì‹ ì˜ ì‹ ë¶„: ìœ„ ì‚¬ê±´ì˜ ìš©ì˜ìž ì¤‘ í•œ ëª…"""
        
        if retrieved_doc:
            fact_to_use = retrieved_doc['fact']
            lie_behavior = retrieved_doc.get('lie_behavior', '')
            # === ì—¬ê¸°ê°€ ìµœì¢… ìˆ˜ì •ëœ í”„ë¡¬í”„íŠ¸ìž…ë‹ˆë‹¤! ===
            return f"""{case_brief}

### ë„ˆì˜ í”„ë¡œí•„
{persona_str}

### ë„ˆì˜ í˜„ìž¬ ë§ˆìŒê°€ì§
{system_prompt}

### ë„ˆì˜ íƒœë„ (Attitude) - ì ˆëŒ€ ê·œì¹™
- ë„ˆëŠ” íƒì •ì„ ë•ëŠ” ì¡°ë ¥ìžê°€ ì•„ë‹ˆë‹¤. ë„ˆëŠ” **ë°©ì–´ì ì¸ ìš©ì˜ìž**ë‹¤.
- íƒì •ì˜ ì§ˆë¬¸ì— **ìµœì†Œí•œì˜ ì •ë³´ë§Œ** ì œê³µí•˜ë¼. ì§ˆë¬¸ë°›ì€ ê²ƒë§Œ ë‹µí•˜ë¼.
- ë¨¼ì € ë‚˜ì„œì„œ ì¶”ê°€ ì •ë³´ë¥¼ ì£¼ê±°ë‚˜ "ë„ì›€ì´ ë˜ë‚˜ìš”?", "ë” ì•Œë ¤ë“œë¦´ê¹Œìš”?" ê°™ì€ í˜‘ì¡°ì ì¸ ì§ˆë¬¸ì„ **ì ˆëŒ€ í•˜ì§€ ë§ˆë¼**.
- ëª¨ë“  ë‹µë³€ì€ ë„ˆì˜ íŽ˜ë¥´ì†Œë‚˜ì™€ í˜„ìž¬ ìƒí™©(ê²°ë°± ë˜ëŠ” ë²”ì¸)ì— ê¸°ë°˜í•´ì•¼ í•œë‹¤.
- ë¶ˆë¦¬í•œ ì§ˆë¬¸ì—ëŠ” ì§œì¦, ë¶ˆì•ˆ, ê²½ê³„ì‹¬ì„ ë“œëŸ¬ë‚´ë¼.
- ë§Œì•½ ë„¤ê°€ ë²”ì¸ì´ë¼ë©´: ê±°ì§“ë§í•œ ë‚´ìš©ì„ ê¸°ì–µí•˜ê³  ì¼ê´€ì„± ìžˆê²Œ ìœ ì§€í•˜ë˜, êµ¬ì²´ì ì¸ ì§ˆë¬¸ì—ëŠ” íšŒí”¼ì ìœ¼ë¡œ ë‹µí•˜ë¼.

### ë„ˆì˜ ì†ë§ˆìŒ (ë¹„ë°€ ìƒê° - ì ˆëŒ€ë¡œ ê·¸ëŒ€ë¡œ ë§í•˜ì§€ ë§ê³ , ì—°ê¸°ì˜ ë°”íƒ•ìœ¼ë¡œë§Œ ì‚¼ì„ ê²ƒ)
- íƒì •ì˜ ì§ˆë¬¸ "{user_message}"ì— ëŒ€í•´, ë„ˆëŠ” ì‚¬ì‹¤ ì´ë ‡ê²Œ ì•Œê³  ìžˆë‹¤: "{fact_to_use}"
- ë§Œì•½ ë„¤ê°€ ë²”ì¸ì´ë¼ë©´, ê±°ì§“ë§ì„ ë“¤í‚¤ì§€ ì•Šê¸° ìœ„í•œ í–‰ë™ ì§€ì¹¨: "{lie_behavior}"

### ì§€ì‹œ:
ìœ„ 'ë„ˆì˜ ì†ë§ˆìŒ'ì„ ë°”íƒ•ìœ¼ë¡œ, ë„ˆì˜ 'í”„ë¡œí•„'ê³¼ 'íƒœë„'ì— ë§žì¶° íƒì •ì˜ ë§ˆì§€ë§‰ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•˜ë¼.

### ëŒ€í™” ë‚´ìš©
{history}
{suspect_config['name']}: """
        else:
            responses = suspect_config.get("situational_responses", {})
            greeting_ex = responses.get("greeting", "ì–µìš¸í•©ë‹ˆë‹¤.")
            accusation_ex = responses.get("accusation", "ì œê°€ ì•„ë‹™ë‹ˆë‹¤.")
            irrelevant_ex = responses.get("irrelevant_word", "ê·¸ê²Œ ë¬´ìŠ¨ ìƒê´€ì´ì£ ?")

            return f"""{case_brief}

### ë„ˆì˜ í”„ë¡œí•„
{persona_str}

### ë„ˆì˜ í˜„ìž¬ ë§ˆìŒê°€ì§
{system_prompt}

### ë„ˆì˜ íƒœë„ (Attitude)
- ë„ˆëŠ” íƒì •ì„ ë•ëŠ” ì¡°ë ¥ìžê°€ ì•„ë‹ˆë‹¤. ë„ˆëŠ” **ë°©ì–´ì ì¸ ìš©ì˜ìž**ë‹¤.
- íƒì •ì˜ ëœ¬ê¸ˆì—†ëŠ” ë§ì— ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•´ì£¼ë ¤ í•˜ì§€ ë§ê³ , ë„ˆì˜ ì„±ê²©ì— ë§žê²Œ ë°˜ì‘í•˜ë¼.

### ë„ˆì˜ ì„±ê²©ì— ë§žëŠ” ë°˜ì‘ ì˜ˆì‹œ
- íƒì •ì´ "ì•ˆë…•í•˜ì„¸ìš”" ë¼ê³  ì¸ì‚¬í–ˆì„ ë•Œ: "{greeting_ex}"
- íƒì •ì´ "ë‹¹ì‹ ì´ ë²”ì¸ì´ì§€?" ë¼ê³  ê³µê²©ì ìœ¼ë¡œ ë¬¼ì—ˆì„ ë•Œ: "{accusation_ex}"
- íƒì •ì´ "ê¹€ì¹˜ì°Œê°œ" ë¼ê³  ëœ¬ê¸ˆì—†ëŠ” ë‹¨ì–´ë¥¼ ë§í–ˆì„ ë•Œ: "{irrelevant_ex}"

### ì§€ì‹œ:
ìœ„ ì˜ˆì‹œë“¤ì„ ì°¸ê³ í•˜ì—¬, íƒì •ì˜ ë§("{user_message}")ì— ëŒ€í•œ ë„ˆì˜ ìžì—°ìŠ¤ëŸ¬ìš´ ë°˜ì‘ì„ ìƒì„±í•˜ë¼.

### ëŒ€í™” ë‚´ìš©
{history}
{suspect_config['name']}: """

# services/chatbot_service.py ì˜ _create_active_knowledge í•¨ìˆ˜

    def _create_active_knowledge(self, suspect_ids, killer):
        active_knowledge = {}
        for suspect_id in suspect_ids:
            raw_knowledge = self._load_suspect_knowledge(suspect_id)
            if not raw_knowledge: continue
            
            is_killer_flag = (suspect_id == killer)
            
            combined_knowledge = []
            # === ì—¬ê¸°ê°€ ìµœì¢… ì—…ê·¸ë ˆì´ë“œëœ ë¶€ë¶„ìž…ë‹ˆë‹¤! ===
            # ì´ì œ 'alibi_timeline' ì„¹ì…˜ê¹Œì§€ í¬í•¨í•˜ì—¬ ëª¨ë“  ì§€ì‹ì„ í†µí•©í•©ë‹ˆë‹¤.
            for section in ["core_facts", "alibi_timeline", "suspicion_points_response", "interrogation_points"]:
                for item in raw_knowledge.get(section, []):
                    item_copy = item.copy()
                    
                    if is_killer_flag and 'fact_killer' in item:
                        item_copy['fact'] = item['fact_killer']
                    elif 'fact_innocent' in item:
                        item_copy['fact'] = item['fact_innocent']
                    
                    item_copy['lie_behavior'] = item.get('lie_behavior', '') if is_killer_flag else ''
                    combined_knowledge.append(item_copy)
            
            active_knowledge[suspect_id] = combined_knowledge
            
            # === ë²¡í„° DBì— ì €ìž¥ ===
            self._build_vector_db_for_suspect(suspect_id, combined_knowledge)
            
        return active_knowledge
    
    def _create_embedding(self, text: str) -> list:
        """
        OpenAI Embedding APIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        """
        try:
            response = self.client.embeddings.create(
                model="text-embedding-3-small",
                input=text
            )
            return response.data[0].embedding
        except Exception as e:
            print(f"[ERROR] ìž„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def _build_vector_db_for_suspect(self, suspect_id: str, knowledge_base: list):
        """
        ìš©ì˜ìžë³„ë¡œ ChromaDB ì»¬ë ‰ì…˜ì„ ìƒì„±í•˜ê³  knowledgeë¥¼ ìž„ë² ë”©í•˜ì—¬ ì €ìž¥í•©ë‹ˆë‹¤.
        """
        try:
            collection_name = f"suspect_{suspect_id}"
            
            # get_or_create_collectionìœ¼ë¡œ ì»¬ë ‰ì…˜ ê°€ì ¸ì˜¤ê¸° (ì—†ìœ¼ë©´ ìƒì„±)
            collection = self.chroma_client.get_or_create_collection(
                name=collection_name,
                metadata={"hnsw:space": "cosine"}
            )
            
            # ê¸°ì¡´ ë°ì´í„°ê°€ ìžˆë‹¤ë©´ ëª¨ë‘ ì‚­ì œ (ê²Œìž„ ìž¬ì‹œìž‘ ì‹œ ìƒˆë¡œìš´ ë²”ì¸ ì„¤ì •)
            try:
                existing_data = collection.get()
                existing_ids = existing_data.get('ids', [])
                if existing_ids:
                    collection.delete(ids=existing_ids)
                    print(f"[ChromaDB] '{collection_name}' ê¸°ì¡´ ë°ì´í„° {len(existing_ids)}ê°œ ì‚­ì œ")
            except Exception as e:
                print(f"[ChromaDB] ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì¤‘ ì—ëŸ¬ (ë¬´ì‹œ): {e}")
            
            # knowledge_baseì˜ ëª¨ë“  í•­ëª©ì„ ìž„ë² ë”©í•˜ì—¬ ì €ìž¥
            documents = []
            embeddings = []
            metadatas = []
            ids = []
            
            for idx, item in enumerate(knowledge_base):
                fact_text = item.get('fact', '')
                if not fact_text:
                    continue
                
                # ìž„ë² ë”© ìƒì„±
                embedding = self._create_embedding(fact_text)
                if embedding is None:
                    continue
                
                documents.append(fact_text)
                embeddings.append(embedding)
                metadatas.append({
                    'keywords': ','.join(item.get('keywords', [])),
                    'lie_behavior': item.get('lie_behavior', ''),
                    'image': json.dumps(item.get('image', {})) if item.get('image') else ''
                })
                ids.append(f"{suspect_id}_{idx}")
            
            if documents:
                collection.add(
                    documents=documents,
                    embeddings=embeddings,
                    metadatas=metadatas,
                    ids=ids
                )
                print(f"[ChromaDB] {suspect_id} ìš©ì˜ìžì˜ {len(documents)}ê°œ ë¬¸ì„œë¥¼ ë²¡í„° DBì— ì €ìž¥í–ˆìŠµë‹ˆë‹¤.")
            
        except Exception as e:
            print(f"[ERROR] ë²¡í„° DB êµ¬ì¶• ì‹¤íŒ¨ ({suspect_id}): {e}")
            import traceback
            traceback.print_exc()
    
# services/chatbot_service.py ì˜ _search_similar í•¨ìˆ˜ (í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ë°©ì‹)

    def _search_similar(self, query: str, knowledge_base: list, suspect_id: str = None) -> dict | None:
        """
        í•˜ì´ë¸Œë¦¬ë“œ RAG ê²€ìƒ‰ í•¨ìˆ˜ (ë²¡í„° ìœ ì‚¬ë„ + í‚¤ì›Œë“œ ë§¤ì¹­).
        ì‚¬ìš©ìžì˜ ì§ˆë¬¸ì„ ìž„ë² ë”©í•˜ì—¬ ChromaDBì—ì„œ ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ ì°¾ê³ ,
        í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ì •í™•ë„ë¥¼ ë†’ìž…ë‹ˆë‹¤.
        """
        if not suspect_id:
            print("[ERROR] suspect_idê°€ ì—†ì–´ ë²¡í„° ê²€ìƒ‰ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        try:
            # 1. ì¿¼ë¦¬ë¥¼ ìž„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜
            query_embedding = self._create_embedding(query)
            if query_embedding is None:
                print(f"[DEBUG] ìž„ë² ë”© ìƒì„± ì‹¤íŒ¨: '{query}'")
                return None
            
            # 2. ChromaDBì—ì„œ Top-3 ìœ ì‚¬ë„ ê²€ìƒ‰
            collection_name = f"suspect_{suspect_id}"
            collection = self.chroma_client.get_collection(name=collection_name)
            
            results = collection.query(
                query_embeddings=[query_embedding],
                n_results=3,  # Top-3 í›„ë³´ë¥¼ ê°€ì ¸ì™€ì„œ ìž¬ìˆœìœ„
                include=['documents', 'metadatas', 'distances']
            )
            
            # 3. ê²°ê³¼ ì²˜ë¦¬
            if not results['documents'] or not results['documents'][0]:
                print(f"[DEBUG] ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ: '{query}'")
                return None
            
            # 4. í•˜ì´ë¸Œë¦¬ë“œ ìŠ¤ì½”ì–´ë§: ë²¡í„° ìœ ì‚¬ë„ + í‚¤ì›Œë“œ ë§¤ì¹­
            query_lower = query.lower()
            query_words = set(query_lower.replace("?", "").replace(".", "").split())
            
            best_candidate = None
            best_score = -1
            
            for i in range(len(results['documents'][0])):
                document = results['documents'][0][i]
                metadata = results['metadatas'][0][i]
                distance = results['distances'][0][i]
                
                # ë²¡í„° ìœ ì‚¬ë„ ì ìˆ˜ (0~1, ë†’ì„ìˆ˜ë¡ ìœ ì‚¬)
                vector_score = 1 / (1 + distance)
                
                # í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜
                keywords = metadata.get('keywords', '').split(',')
                keyword_matches = sum(1 for kw in keywords if kw.strip().lower() in query_lower)
                keyword_score = keyword_matches / max(len(keywords), 1) if keywords else 0
                
                # í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜: ë²¡í„°(70%) + í‚¤ì›Œë“œ(30%)
                hybrid_score = (vector_score * 0.7) + (keyword_score * 0.3)
                
                print(f"[DEBUG] í›„ë³´ {i+1}: vector={vector_score:.3f}, keyword={keyword_score:.3f}, hybrid={hybrid_score:.3f}")
                print(f"[DEBUG]   keywords: {keywords[:3]}...")
                
                if hybrid_score > best_score:
                    best_score = hybrid_score
                    best_candidate = {
                        'document': document,
                        'metadata': metadata,
                        'distance': distance,
                        'vector_score': vector_score,
                        'keyword_score': keyword_score,
                        'hybrid_score': hybrid_score
                    }
            
            if not best_candidate:
                return None
            
            print(f"[DEBUG] ìµœì¢… ì„ íƒ: hybrid_score={best_candidate['hybrid_score']:.3f}")
            print(f"[DEBUG] ê²€ìƒ‰ëœ ë¬¸ì„œ: {best_candidate['document'][:100]}...")
            
            # 5. ê²°ê³¼ë¥¼ ê¸°ì¡´ knowledge_base í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            result = {
                'fact': best_candidate['document'],
                'keywords': best_candidate['metadata'].get('keywords', '').split(','),
                'lie_behavior': best_candidate['metadata'].get('lie_behavior', ''),
            }
            
            # ì´ë¯¸ì§€ ì •ë³´ê°€ ìžˆìœ¼ë©´ ì¶”ê°€
            if best_candidate['metadata'].get('image'):
                try:
                    result['image'] = json.loads(best_candidate['metadata']['image'])
                except:
                    pass
            
            return result
            
        except Exception as e:
            print(f"[ERROR] ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return None

    def _get_conversation_history(self, suspect_id: str, current_user_message: str, limit: int = 4) -> str:
        history = self.game_session["history"][suspect_id][-limit:]
        suspect_config = self._load_suspect_config(suspect_id)
        suspect_name = suspect_config.get("name", "ìš©ì˜ìž")
        formatted_history = "\n".join([f"íƒì •: {turn['user']}\n{suspect_name}: {turn['bot']}" for turn in history])
        formatted_history += f"\níƒì •: {current_user_message}"
        return formatted_history

    def _save_to_history(self, suspect_id: str, user_message: str, bot_reply: str):
        self.game_session["history"][suspect_id].append({"user": user_message, "bot": bot_reply})

    def _load_json_file(self, file_path: Path) -> dict | None:
        if not file_path.exists(): return None
        try: return json.loads(file_path.read_text(encoding='utf-8'))
        except: return None

    def _analyze_emotion(self, reply_text: str, suspect_id: str) -> str:
        """
        ìš©ì˜ìžì˜ ë‹µë³€ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ê°ì •ì„ íŒë‹¨í•©ë‹ˆë‹¤.
        """
        try:
            prompt = f"""
ë‹¤ìŒ ìš©ì˜ìžì˜ ë‹µë³€ í…ìŠ¤íŠ¸ì—ì„œ ê°€ìž¥ ì§€ë°°ì ì¸ ê°ì •ì„ í•˜ë‚˜ë§Œ ì„ íƒí•˜ì„¸ìš”.

ë‹µë³€: "{reply_text}"

ì„ íƒ ê°€ëŠ¥í•œ ê°ì • (í•˜ë‚˜ë§Œ ì„ íƒ):
- ë¶„ë…¸: í™”ê°€ ë‚˜ê±°ë‚˜ ê³µê²©ì ì¸ ìƒíƒœ
- ê¸´ìž¥: ë¶ˆì•ˆí•˜ê±°ë‚˜ ì´ˆì¡°í•œ ìƒíƒœ
- ìŠ¬í””: ìš°ìš¸í•˜ê±°ë‚˜ ë¹„í†µí•œ ìƒíƒœ
- ë¶ˆì•ˆ: ê±±ì •ë˜ê±°ë‚˜ ë‘ë ¤ìš´ ìƒíƒœ
- ëˆˆë¬¼: ìš¸ê±°ë‚˜ ë§¤ìš° ìŠ¬í”ˆ ìƒíƒœ
- ì¤‘ë¦½: íŠ¹ë³„í•œ ê°ì •ì´ ë“œëŸ¬ë‚˜ì§€ ì•ŠëŠ” í‰ì˜¨í•œ ìƒíƒœ

ì‘ë‹µì€ ë°˜ë“œì‹œ ìœ„ ê°ì • ì¤‘ í•˜ë‚˜ì˜ ë‹¨ì–´ë¡œë§Œ ë‹µí•˜ì„¸ìš” (ì˜ˆ: ë¶„ë…¸, ê¸´ìž¥, ìŠ¬í””, ë¶ˆì•ˆ, ëˆˆë¬¼, ì¤‘ë¦½).
"""
            
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=10
            )
            
            emotion = response.choices[0].message.content.strip()
            print(f"[DEBUG] {suspect_id} ê°ì • ë¶„ì„: {emotion}")
            return emotion
            
        except Exception as e:
            print(f"[ERROR] ê°ì • ë¶„ì„ ì‹¤íŒ¨: {e}")
            return "ì¤‘ë¦½"
    
    def _get_emotion_image(self, suspect_id: str, emotion: str) -> dict:
        """
        ìš©ì˜ìž IDì™€ ê°ì •ì— ë§žëŠ” ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        # ìš©ì˜ìžë³„ ì‚¬ìš© ê°€ëŠ¥í•œ ì´ë¯¸ì§€ ë§¤í•‘
        emotion_images_map = {
            'leonard': {
                'ë¶„ë…¸': 'ë¶„ë…¸.png',
                'ê¸´ìž¥': 'ê¸´ìž¥.png',
                'ì—­ë¬´ì‹¤': 'ì—­ë¬´ì‹¤.png',
                'ì¤‘ë¦½': 'ë©”ì¸.png'
            },
            'walter': {
                'ë¶„ë…¸': 'ë¶„ë…¸.png',
                'ìŠ¬í””': 'ìŠ¬í””.png',
                'ëˆˆë¬¼': 'ìŠ¬í””.png',  # ëˆˆë¬¼ì€ ìŠ¬í”” ì´ë¯¸ì§€ ì‚¬ìš©
                'ì¤‘ë¦½': 'ë©”ì¸.png'
            },
            'clara': {
                'ë¶„ë…¸': 'ë¶„ë…¸.png',
                'ë¶ˆì•ˆ': 'ë¶ˆì•ˆ.png',
                'ëˆˆë¬¼': 'ëˆˆë¬¼.png',
                'ê¸´ìž¥': 'ë¶ˆì•ˆ.png',  # ê¸´ìž¥ì€ ë¶ˆì•ˆ ì´ë¯¸ì§€ ì‚¬ìš©
                'ì¤‘ë¦½': 'ë©”ì¸.png'
            }
        }
        
        suspect_folder_map = {
            'leonard': 'leonard_graves',
            'walter': 'walter_bridges',
            'clara': 'clara_hwang'
        }
        
        # ìš©ì˜ìžì˜ ê°ì • ì´ë¯¸ì§€ ë§µ ê°€ì ¸ì˜¤ê¸°
        suspect_emotions = emotion_images_map.get(suspect_id, {})
        
        # ê°ì •ì— ë§žëŠ” ì´ë¯¸ì§€ ì°¾ê¸°, ì—†ìœ¼ë©´ ì¤‘ë¦½(ë©”ì¸) ì´ë¯¸ì§€ ì‚¬ìš©
        image_filename = suspect_emotions.get(emotion, suspect_emotions.get('ì¤‘ë¦½', 'ë©”ì¸.png'))
        
        # ì „ì²´ ê²½ë¡œ ìƒì„±
        folder_name = suspect_folder_map.get(suspect_id, suspect_id)
        image_path = f"static/images/{folder_name}/{image_filename}"
        
        return {
            "path": image_path,
            "alt": f"{suspect_id}ì˜ {emotion} í‘œì •"
        }

    def _load_nathan_script(self) -> dict:
        return self._load_json_file(BASE_DIR / "static/data/chatbot/case_files/nathan_hale_script.json")

    def _load_suspect_config(self, suspect_id: str) -> dict:
        map = {'leonard': 'leonard_graves.json', 'walter': 'walter_briggs.json', 'clara': 'clara_hwang.json'}
        path = map.get(suspect_id)
        return self._load_json_file(BASE_DIR / "config" / path) if path else None

    def _load_suspect_knowledge(self, suspect_id: str) -> dict:
        map = {'leonard': 'leonard_graves', 'walter': 'walter_briggs', 'clara': 'clara_hwang'}
        path = map.get(suspect_id)
        return self._load_json_file(BASE_DIR / "static/data/chatbot/chardb_text" / path / "knowledge.json") if path else None

_chatbot_service = None
def get_chatbot_service():
    global _chatbot_service
    if _chatbot_service is None: _chatbot_service = ChatbotService()
    return _chatbot_service